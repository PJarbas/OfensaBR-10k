# OfensaBR-10k Dataset

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![HuggingFace](https://img.shields.io/badge/ğŸ¤—-HuggingFace-orange)](https://huggingface.co/datasets/pjarbas312/OfensaBR-10k)
[![Language: Portuguese](https://img.shields.io/badge/Language-Portuguese%20(BR)-green)](https://en.wikipedia.org/wiki/Brazilian_Portuguese)

Dataset em portuguÃªs brasileiro para detecÃ§Ã£o de linguagem ofensiva, coletado de redes sociais (Twitter/X). ContÃ©m 10.000 textos balanceados classificados automaticamente.

[English](#english-version) | [PortuguÃªs](#versÃ£o-em-portuguÃªs)

---

## VersÃ£o em PortuguÃªs

### ğŸ“Š VisÃ£o Geral

OfensaBR-10k Ã© um dataset balanceado de textos em portuguÃªs brasileiro coletados do Twitter/X para detecÃ§Ã£o de conteÃºdo ofensivo. Ideal para:

- ğŸ›¡ï¸ Sistemas de moderaÃ§Ã£o de conteÃºdo
- ğŸ” Pesquisa em detecÃ§Ã£o de toxicidade
- ğŸ¤– Treinamento de modelos de classificaÃ§Ã£o
- ğŸ“± AnÃ¡lise de redes sociais em PT-BR
- âœ… Sistemas de guardrails e seguranÃ§a

### ğŸ¯ Estrutura do Dataset

Cada instÃ¢ncia contÃ©m:

```json
{
  "id": 0,
  "text": "Exemplo de texto da rede social",
  "category": "OFFENSIVE",
  "score": 0.87
}
```

**Campos:**
- `id`: Identificador Ãºnico
- `text`: ComentÃ¡rio ou resposta de rede social
- `category`: `OFFENSIVE` ou `NON_OFFENSIVE`
- `score`: ConfianÃ§a do classificador (0.0 a 1.0)

### ğŸ“ˆ EstatÃ­sticas

| MÃ©trica | Valor |
|---------|-------|
| **Total de Textos** | 10.000 |
| **Balanceamento** | 50% OFFENSIVE / 50% NON_OFFENSIVE |
| **Idioma** | 100% PortuguÃªs (BR) |
| **Tamanho MÃ­nimo** | 10 caracteres |
| **Duplicatas** | Removidas |

### ğŸš€ Como Usar

#### Via HuggingFace Datasets

```python
from datasets import load_dataset

# Carregar dataset
dataset = load_dataset("pjarbas312/OfensaBR-10k")

# Acessar dados
for example in dataset['train']:
    print(f"Texto: {example['text']}")
    print(f"Categoria: {example['category']}")
    print(f"Score: {example['score']}\n")
```

#### Download Direto (CSV)

```bash
# Clone o repositÃ³rio
git clone https://github.com/PJarbas/OfensaBR-10k.git
cd OfensaBR-10k

# O dataset estÃ¡ em formato CSV
# Utilize com pandas, polars, ou qualquer biblioteca de sua escolha
```

```python
import pandas as pd

df = pd.read_csv('ofensaBR_10k.csv')
print(df.head())
```

### âš ï¸ Aviso de ConteÃºdo

**Este dataset contÃ©m linguagem ofensiva por design**, incluindo:
- Profanidade e linguagem vulgar
- Insultos e ataques pessoais
- Discurso de Ã³dio e conteÃºdo discriminatÃ³rio
- ExpressÃµes tÃ³xicas e prejudiciais

**Use com responsabilidade e salvaguardas apropriadas.**

### âœ… Usos Apropriados

- Treinar sistemas de moderaÃ§Ã£o de conteÃºdo
- Pesquisa acadÃªmica sobre linguagem ofensiva
- Desenvolvimento de ferramentas de seguranÃ§a online
- Benchmarking de modelos de NLP em PT-BR
- AnÃ¡lise de discurso em redes sociais

### âŒ Usos Inapropriados

- Treinar sistemas para gerar conteÃºdo ofensivo
- AssÃ©dio ou direcionamento de indivÃ­duos
- DiscriminaÃ§Ã£o ou perfilamento
- VigilÃ¢ncia sem consentimento

### ğŸ”¬ Metodologia de CriaÃ§Ã£o

**Coleta de Dados:**
- Fonte: ComentÃ¡rios pÃºblicos do Twitter/X
- Filtros: Apenas portuguÃªs (langdetect), mÃ­nimo 10 caracteres
- Privacidade: Sem usernames, timestamps ou metadados

**ClassificaÃ§Ã£o:**
- Modelo: [Detoxify](https://github.com/unitaryai/detoxify) (`unitary/multilingual-toxic-xlm-roberta`)
- Threshold: 0.5 (score > 0.5 = OFFENSIVE)
- MÃ©todo: ClassificaÃ§Ã£o automÃ¡tica (sem anotaÃ§Ã£o humana)

### âš–ï¸ LimitaÃ§Ãµes Conhecidas

- âš ï¸ **ClassificaÃ§Ã£o automÃ¡tica**: NÃ£o verificado por humanos
- âš ï¸ **ViÃ©s cultural**: Pode refletir vieses presentes nas redes sociais
- âš ï¸ **Contexto limitado**: Textos isolados da thread de conversaÃ§Ã£o
- âš ï¸ **VariaÃ§Ã£o temporal**: Reflete o uso da linguagem no momento da coleta
- âš ï¸ **Nuances perdidas**: Threshold binÃ¡rio pode nÃ£o capturar toda a nuance

### ğŸ“„ LicenÃ§a

Este dataset Ã© licenciado sob a [MIT License](LICENSE).

### ğŸ“š CitaÃ§Ã£o

Se vocÃª usar este dataset em sua pesquisa, por favor cite:

```bibtex
@dataset{ofensabr10k2025,
  title={OfensaBR-10k: A Brazilian Portuguese Dataset for Offensive Language Detection},
  author={Jarbas, Paulo},
  year={2025},
  publisher={HuggingFace},
  howpublished={\url{https://huggingface.co/datasets/pjarbas312/OfensaBR-10k}}
}
```

## English Version

### ğŸ“Š Overview

OfensaBR-10k is a balanced dataset of Brazilian Portuguese texts collected from Twitter/X for offensive content detection. Ideal for:

- ğŸ›¡ï¸ Content moderation systems
- ğŸ” Toxicity detection research
- ğŸ¤– Training classification models
- ğŸ“± PT-BR social media analysis
- âœ… Guardrails and safety systems

### ğŸ¯ Dataset Structure

Each instance contains:

```json
{
  "id": 0,
  "text": "Sample social media text",
  "category": "OFFENSIVE",
  "score": 0.87
}
```

**Fields:**
- `id`: Unique identifier
- `text`: Social media comment or reply
- `category`: `OFFENSIVE` or `NON_OFFENSIVE`
- `score`: Classifier confidence (0.0 to 1.0)

### ğŸ“ˆ Statistics

| Metric | Value |
|--------|-------|
| **Total Texts** | 10,000 |
| **Balance** | 50% OFFENSIVE / 50% NON_OFFENSIVE |
| **Language** | 100% Portuguese (BR) |
| **Min Length** | 10 characters |
| **Duplicates** | Removed |

### ğŸš€ How to Use

#### Via HuggingFace Datasets

```python
from datasets import load_dataset

# Load dataset
dataset = load_dataset("pjarbas312/OfensaBR-10k")

# Access data
for example in dataset['train']:
    print(f"Text: {example['text']}")
    print(f"Category: {example['category']}")
    print(f"Score: {example['score']}\n")
```

#### Direct Download (CSV)

```bash
# Clone the repository
git clone https://github.com/PJarbas/OfensaBR-10k.git
cd OfensaBR-10k

# Dataset is in CSV format
# Use with pandas, polars, or any library of your choice
```

```python
import pandas as pd

df = pd.read_csv('ofensaBR_10k.csv')
print(df.head())
```

### âš ï¸ Content Warning

**This dataset contains offensive language by design**, including:
- Profanity and vulgar language
- Insults and personal attacks
- Hate speech and discriminatory content
- Toxic and harmful expressions

**Use responsibly and with appropriate safeguards.**

### âœ… Appropriate Uses

- Training content moderation systems
- Academic research on offensive language
- Developing online safety tools
- Benchmarking PT-BR NLP models
- Social media discourse analysis

### âŒ Inappropriate Uses

- Training systems to generate offensive content
- Harassment or targeting individuals
- Discrimination or profiling
- Surveillance without consent

### ğŸ”¬ Creation Methodology

**Data Collection:**
- Source: Public Twitter/X comments
- Filters: Portuguese only (langdetect), minimum 10 characters
- Privacy: No usernames, timestamps, or metadata

**Classification:**
- Model: [Detoxify](https://github.com/unitaryai/detoxify) (`unitary/multilingual-toxic-xlm-roberta`)
- Threshold: 0.5 (score > 0.5 = OFFENSIVE)
- Method: Automatic classification (no human annotation)

### âš–ï¸ Known Limitations

- âš ï¸ **Automatic classification**: Not verified by humans
- âš ï¸ **Cultural bias**: May reflect biases present in social media
- âš ï¸ **Limited context**: Texts isolated from conversation threads
- âš ï¸ **Temporal variation**: Reflects language use at collection time
- âš ï¸ **Lost nuances**: Binary threshold may not capture all nuance

### ğŸ“„ License

This dataset is licensed under the [MIT License](LICENSE).

### ğŸ“š Citation

If you use this dataset in your research, please cite:

```bibtex
@dataset{ofensabr10k2025,
  title={OfensaBR-10k: A Brazilian Portuguese Dataset for Offensive Language Detection},
  author={Jarbas, Paulo},
  year={2025},
  publisher={HuggingFace},
  howpublished={\url{https://huggingface.co/datasets/pjarbas312/OfensaBR-10k}}
}
```
